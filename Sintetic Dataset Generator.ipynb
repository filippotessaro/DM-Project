{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sintetic Dataset Generator**\n",
    "### **Input Data**\n",
    "#### Fill the *association_rules* array like in this example\n",
    "It is a tuple representing:\n",
    "- The 1<sup>st</sup> element is the **left** part of the Association Rule\n",
    "- The 2<sup>nd</sup> element is the **right** part of the Association Rule\n",
    "- The 3<sup>rd</sup> element is the **confidence** of the Association Rule (it is used for defining how likely is the generation of a similar basket)\n",
    "- The 4<sup>th</sup> element is the **interest** of the Association Rule (currently it is not used)\n",
    "\n",
    "#### Basket *Dataset size*\n",
    "In the other cell you can define the number of basket to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = []\n",
    "association_rules.append((['butter', 'curd'], ['milk'], 67, 67))\n",
    "association_rules.append((['curd', 'milk'], ['butter'], 23, 22))\n",
    "association_rules.append((['butter', 'whipped/sour'], ['milk'], 67, 66))\n",
    "association_rules.append((['butter', 'milk'], ['yogurt'], 23, 22))\n",
    "association_rules.append((['butter', 'yogurt'], ['milk'], 64, 64))\n",
    "association_rules.append((['curd', 'whipped/sour'], ['milk'], 54, 53))\n",
    "association_rules.append((['curd', 'milk'], ['yogurt'], 34, 33))\n",
    "association_rules.append((['curd', 'yogurt'], ['milk'], 58, 58))\n",
    "association_rules.append((['frozen', 'yogurt'], ['milk'], 50, 50))\n",
    "association_rules.append((['frozen', 'milk'], ['yogurt'], 23, 22))\n",
    "association_rules.append((['rolls/buns', 'yogurt'], ['milk'], 42, 42))\n",
    "association_rules.append((['whipped/sour', 'yogurt'], ['milk'], 55, 55))\n",
    "association_rules.append((['milk', 'whipped/sour'], ['yogurt'], 34, 34))\n",
    "association_rules.append((['onions', 'other'], ['vegetables'], 40, 39))\n",
    "association_rules.append((['onions', 'vegetables'], ['other'], 60, 59))\n",
    "association_rules.append((['vegetables', 'yogurt'], ['whipped/sour'], 22, 21))\n",
    "association_rules.append((['whipped/sour', 'yogurt'], ['vegetables'], 26, 25))\n",
    "association_rules.append((['vegetables', 'whipped/sour'], ['yogurt'], 31, 31))\n",
    "association_rules.append((['UHT-milk'], ['vegetables'], 20, 19))\n",
    "association_rules.append((['liquor'], ['beer'], 47, 47))\n",
    "association_rules.append((['red/blush'], ['beer'], 38, 37))\n",
    "association_rules.append((['berries'], ['fruit'], 37, 36))\n",
    "association_rules.append((['berries'], ['other'], 21, 20))\n",
    "association_rules.append((['butter'], ['milk'], 46, 44))\n",
    "association_rules.append((['butter'], ['vegetables'], 20, 17))\n",
    "association_rules.append((['candy'], ['chocolate'], 20, 19))\n",
    "association_rules.append((['curd'], ['milk'], 47, 45))\n",
    "association_rules.append((['curd'], ['yogurt'], 27, 26))\n",
    "association_rules.append((['dessert'], ['milk'], 28, 27))\n",
    "association_rules.append((['domestic'], ['milk'], 24, 22))\n",
    "association_rules.append((['eggs'], ['rolls/buns'], 24, 22))\n",
    "association_rules.append((['frozen'], ['milk'], 24, 21))\n",
    "association_rules.append((['grapes'], ['fruit'], 42, 41))\n",
    "association_rules.append((['onions'], ['fruit'], 25, 24))\n",
    "association_rules.append((['other'], ['fruit'], 24, 19))\n",
    "association_rules.append((['pip'], ['fruit'], 37, 35))\n",
    "association_rules.append((['root'], ['fruit'], 37, 34))\n",
    "association_rules.append((['fruit/vegetable'], ['soda'], 24, 22))\n",
    "association_rules.append((['grapes'], ['other'], 28, 27))\n",
    "association_rules.append((['hard'], ['milk'], 29, 28))\n",
    "association_rules.append((['herbs'], ['other'], 47, 47))\n",
    "association_rules.append((['herbs'], ['vegetables'], 43, 42))\n",
    "association_rules.append((['sliced'], ['milk'], 36, 36))\n",
    "association_rules.append((['soft'], ['milk'], 35, 34))\n",
    "association_rules.append((['whipped/sour'], ['milk'], 46, 44))\n",
    "association_rules.append((['yogurt'], ['milk'], 43, 39))\n",
    "association_rules.append((['milk'], ['yogurt'], 20, 12))\n",
    "association_rules.append((['misc.'], ['soda'], 25, 25))\n",
    "association_rules.append((['onions'], ['other'], 45, 45))\n",
    "association_rules.append((['onions'], ['vegetables'], 30, 29))\n",
    "association_rules.append((['other'], ['vegetables'], 24, 19))\n",
    "association_rules.append((['packaged'], ['vegetables'], 43, 43))\n",
    "association_rules.append((['pastry'], ['rolls/buns'], 20, 17))\n",
    "association_rules.append((['sliced'], ['yogurt'], 21, 21))\n",
    "association_rules.append((['water'], ['soda'], 26, 23))\n",
    "association_rules.append((['whipped/sour'], ['vegetables'], 24, 22))\n",
    "association_rules.append((['vegetables'], ['whole'], 25, 15))\n",
    "association_rules.append((['whole'], ['vegetables'], 38, 31))\n",
    "association_rules.append((['whipped/sour'], ['yogurt'], 28, 26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_available = ['AA', 'BB', 'CC', 'DD', 'EE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Import** section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Function** definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data\n",
    "def displayAssociationRules(ars):\n",
    "    arules = pd.DataFrame(ars)\n",
    "    arules.columns = [\"From\", \"To\", \"Confidence\", \"Interest\"]\n",
    "    arules.sort_values(\"Confidence\", ascending=False)\n",
    "    display(arules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the Association Rules, get the set of all products\n",
    "# In order to be compatible with the rest of the script, it returns a list object (not a set)\n",
    "def getProducts(dataset):    \n",
    "    products = []\n",
    "    # Extract data from each Association Rule\n",
    "    for ar in dataset:\n",
    "        for item in ar[0]:\n",
    "            products.append(item)\n",
    "        for item in ar[1]:\n",
    "            products.append(item)\n",
    "    products = list(set(products))\n",
    "    return products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "#### **Basket Generation**\n",
    "There are two ways to generate a basket. The *which* variable defines with half probabability either one way or the other.\n",
    "- **Completely random**, it picks a sample of the whole list of products, and extract *k* elements, where *k* is a random variable having the highest probability on 1, and the smallest on *n*, the number of available products. It is a bounded monotonic decreasing distribution.\n",
    "- **Based on the Association Rules**, accordingly to the confidences of the association rules, it extracts one of them. Then, it selects k, the size of the basket, it is a random variable centered on the half of the left side size. Finally, it decides whether to include the right item or not into the basket. This probability is given by the confidence of the choosen Association Rule too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBasket(ars, arbased, mixed=False, prod_AR_source=True, source=None):\n",
    "    \n",
    "    if prod_AR_source:\n",
    "        products = getProducts(ars)\n",
    "    else:\n",
    "        products = source\n",
    "    n = len(products)\n",
    "    \n",
    "    which_prob = [1 - arbased, arbased]\n",
    "    which = np.random.choice([0, 1], p=which_prob)\n",
    "    # 0 --> Completely Random\n",
    "    # 1 --> Association Rule - Based\n",
    "    \n",
    "    if which == 0:\n",
    "                \n",
    "        # In order to define a decreasing probability, I define an array with length n\n",
    "        # Where each element prob_dist[i] = n-i normalized with respect to the sum of \n",
    "        # the first n integer n*(n+1)/2 (in order to get a probability distribution)\n",
    "        prob_dist = [i**5 + 1 for i in range(n)]\n",
    "        prob_dist_sum = sum(prob_dist)\n",
    "        prob_dist = [p/prob_dist_sum for p in prob_dist]\n",
    "        prob_dist = prob_dist[::-1]\n",
    "        \n",
    "        # Create an array representing how many item it is possible extract\n",
    "        # So as we can choose a number based on the probability\n",
    "        how_many_products = list(range(1, n + 1))    \n",
    "        k = np.random.choice(how_many_products, p=prob_dist)\n",
    "\n",
    "        # Pick a sample of size k\n",
    "        prod = random.sample(products, k)\n",
    "\n",
    "    else:\n",
    "    \n",
    "        # Get the confidences of the Association Rules\n",
    "        # Along with the sum of that values, in order to normalize the confidences array\n",
    "        confidences = [ar[2] for ar in ars]\n",
    "        conf_sum = sum(confidences)\n",
    "        confidences = [conf/conf_sum for conf in confidences]\n",
    "        \n",
    "        # Create an array with the indexes of the possible AR\n",
    "        ar_number = len(ars)        \n",
    "        which_ar_pick = list(range(ar_number))\n",
    "        \n",
    "        # Take one of the Association Rules.\n",
    "        # Use the confidences in order to define their probability distribution\n",
    "        index = np.random.choice(which_ar_pick, p=confidences)\n",
    "        AR = ars[index]        \n",
    "        left_side = AR[0]\n",
    "        rigth_side = AR[1]\n",
    "        \n",
    "        # As in the other case, define how many item it is possible to select\n",
    "        # array_sum is used for normalizing the probabilities\n",
    "        left_size = len(left_side)\n",
    "        array_sum = left_size * (left_size + 1) * 0.5\n",
    "        \n",
    "        # Number of products available, at least one.\n",
    "        # The probability distribution is centered on the half of the left side size of the AR\n",
    "        how_many_products = list(range(1, left_size + 1))  \n",
    "        \n",
    "        # Creating the distribution for the basket size (at least)\n",
    "        increasing = [5*i for i in range(2, 2 + math.floor(left_size/2))]\n",
    "        decreasing = [2*i - 1.0/(2*i) for i in list(range(1, 1 + math.ceil(left_size/2)))[::-1]]\n",
    "        size_dist = increasing + decreasing\n",
    "        sum_array = sum(size_dist)\n",
    "        size_dist = [p/sum_array for p in size_dist]\n",
    "\n",
    "        # Pick k, and k products on the left side\n",
    "        k = np.random.choice(how_many_products, p=size_dist)        \n",
    "        prod = random.sample(left_side, k)\n",
    "\n",
    "        # Consider to add the right element with probability proportional to the confidence of the AR\n",
    "        right_prob = confidences[index]\n",
    "        included = np.random.binomial(size=1, n=1, p=right_prob)[0]\n",
    "\n",
    "        # If lucky\n",
    "        if included == 1:\n",
    "            prod.append(rigth_side[0])\n",
    "            \n",
    "        if mixed:\n",
    "            # Add some random product\n",
    "            prob_dist = [i**9 + 1 for i in range(n)]\n",
    "            prob_dist_sum = sum(prob_dist)\n",
    "            prob_dist = [p/prob_dist_sum for p in prob_dist]\n",
    "            prob_dist = prob_dist[::-1]\n",
    "            how_many_products = list(range(1, n + 1))    \n",
    "            k = np.random.choice(how_many_products, p=prob_dist)\n",
    "            prod_to_add = random.sample(products, k)\n",
    "            for product in prod_to_add:\n",
    "                prod.append(product)\n",
    "            \n",
    "    # Remove eventual duplicates\n",
    "    prod = list(set(prod))\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(ars, size, arbased=0.5, mixed=False, prod_AR_source=True, source=None):\n",
    "    sintetic = []\n",
    "    for _ in range(size):\n",
    "        sintetic.append(generateBasket(ars, arbased, mixed, prod_AR_source=prod_AR_source, source=source))\n",
    "    return sintetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Save on file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(ds, fname, aligned=True, with_title=False):\n",
    "    \n",
    "    # Get the maximum number of item in a basket\n",
    "    max_basket_size = 0\n",
    "    for basket in ds:\n",
    "        if len(basket) > max_basket_size:\n",
    "            max_basket_size = len(basket)\n",
    "    \n",
    "    file = open(fname, \"w+\")\n",
    "    \n",
    "    # Write the title if required\n",
    "    if with_title:\n",
    "        title = \"\"\n",
    "        for i in range(1, max_basket_size + 1):\n",
    "            title += \"Product\" + str(i) + \",\"\n",
    "        title = title[:-1]\n",
    "        file.write(title + \"\\n\")\n",
    "    \n",
    "    # To CSV\n",
    "    for basket in ds:\n",
    "        bskt = \"\"\n",
    "        for item in basket:\n",
    "            bskt += item + \",\"\n",
    "        for _ in range(max_basket_size - len(basket)):            \n",
    "            bskt += \",\"\n",
    "        bskt = bskt[:-1]\n",
    "        file.write(bskt + \"\\n\")\n",
    "        \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generateDataset(association_rules, 10000, arbased=0.6, mixed=True, prod_AR_source=True, source=products_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "export(dataset, \"./data/sintetic/test_12.csv\", with_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
